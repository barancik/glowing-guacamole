\chapter{Data}
\addcontentsline{toc}{chapter}{Data}

\section{Test Data}

We use data sets from the English-to-Czech Translation Task of the Workshop on
Statistical Machine Translation (WMT) from the years 2011 to 2014.

All of these datasets consist of one file with the original English source sentences,
several files with Czech hypotheses (outputs of MT systems) and one file with corresponding 
reference sentences. Data from each year of the WMT competition differ in the 
number of MT systems and the length of the source files (see \Tref{wmt-data}). 

%We perform morphological 
%analysis and tagging of the MT outputs and the reference sentences using 
%Morphodita \citep{morphodita}. \todo{nekde morphodita, nekde jeste morce}

\begin{table}[h]
\centering
\begin{tabular}{l|l|l|l|l}
      & systems & sentences & official score & publication\\
\hline
WMT11 & 14/10    & 3003      & “$ >= $ others”      & \cite{wmt11}  \\
WMT12 & 13          & 3003      & “$ > $ others”      & \cite{wmt12}  \\
WMT13 & 14/12    & 3000      & \textit{Expected Wins} & \cite{wmt13}  \\
WMT14 & 10          & 3003      & \textit{TrueSkill}   & \cite{wmt14}
\end{tabular}
\caption{Overview of WMT datasets. Number of systems translating from English 
to Czech (all MT systems / systems that were manually evaluated), number of 
source sentences and the official method for computing the absolute human 
judgement score.}
\label{wmt-data}
\end{table}

During the manual evaluation of WMT competitions, human judges fluent in both
the source and the target language scores five hypotheses from the best to
the worst translation. Thus, the human evaluation of hypotheses is available 
as~a~relative ranking of performance of five systems for~a~sentence. 

There are many ways to compute the absolute system score from this relative
ranking. The official methods for each year are presented in \Tref{wmt-data} 
and we refer to these as the \textit{gold standard}. The official method is
different for every year. Therefore, to make our evaluation internally 
consistent, we also compute another absolute score for every year using the 
“$ >$ others” method \citep{bojar-grains}, which was the WMT12 official system
score. This score is computed simply as $\frac{wins}{wins+loses} $, i.e., the 
score is~based on~how frequently the system is judged to be better than 
other systems, ties among several systems are ignored. We refer to this 
interpretation of human judgments as a \textit{silver standard} to distinguish
it from the official system scores. % todo: chcu to tu jeste zduvodnit, proc > others??

The performance of an evaluation metric in MT is commonly computed as the
Pearson correlation coefficient or alternatively as the Spearman rank 
correlation between the automatic metric and human judgment. 

The Pearson correlation coefficient $\rho$ is defined by the following formula:

\begin{equation*}
\rho(H,M) = \frac{ \sum_{i=1}^{n}{(H_i - \tilde{H})(M_i - \tilde{M})}}{ \sqrt{ \sum_{i=1}^{n}{(H_i - \tilde{H})^2} }  \sqrt{ \sum_{i=1}^{n}{(M_i - \tilde{M})^2} } } 
\end{equation*}

where $H$ is the vector of human scores (i.e. gold or silver standard here) and 
$M$ is the vector of corresponding scores predicted by a certain metric. 
$\tilde{H}$ a $\tilde{M}$ are their means, respectively. 

The Spearman correlation coefficient $r_{s} $ is defined as the Pearson 
correlation coefficient between the rank variables -- all human scores and  
metric’s scores of MT systems are converted into ranks $r(H)$ and $r(M)$.

\begin{equation*}
r_{s}(H,M) = \rho(r(H),r(M))
\end{equation*}

Both~correlations estimate the linear dependency between two sets of values and 
range from -1 (perfect negative linear relationship) to 1 (perfect linear correlation). 

In our experiments, we use the Pearson correlation coefficient as it takes into 
account the distances between the system scores, thus it should be more 
reliable for similarly evaluated systems \citep{machacek-bojar-2014-results}. 
\todo{tu to jeste trochu rozsirit, kdyz uz
to tu je vysvetleny - ze Spearman ignoruje jak moc jsou systemy od sebe vzdaleny}

%
%WMT13
%We measured the quality of system-level metrics’ scores using the Spearman’s rank correlation coefficient $\rho$. For each direction of translation we converted the official human scores into ranks. For each metric, we converted the metric’s scores of systems in a given direction into ranks. Since there were no ties in the rankings, we used the simplified formula to compute the Spearman’s $\rho$. 
%
%\begin{equation*}
%r_{s} = 1 -  \frac{6\sum{d_i^{2}}}{n(n^{2}-1)} 
%\end{equation*}
%where $d_{i}$ is the difference between the rank for system$_{i}$ and n is the number of systems. The possible values of range between 1 (where all systems are ranked in the same order) and -1 (where the systems are ranked in the reverse order). 
%
%\begin{equation*}
%r_{s} = r_{p}(r(H_{i}),r(M_{i}))
%\end{equation*}

\section{Sources of Czech Paraphrases}
We use the following available sources of Czech paraphrases.

\subsection{Czech WordNet}
Czech WordNet \citep{czech-wordnet} was created (by NLP Centre at the faculty of Informatics, Masaryk University ) as part of the EuroWordNet project \todo{citace}. 
It's aim was to build a semantic network in several languages that share one common core structure.

It contains 28,201 synsets, each synset represents a word sense and lists words and phrases which can be used to express the meaning. 
Synsets can include a definition of its meaning but only few have it filled.
Recently, linguistic students were asked to write missing definitions, however they are not included in the Czech WordNet yet. \citep{Rambousek:2017}

Unfortunately, this original, larger version of Czech Wordnet is only available under closed and paid licence through the ELDA/ELRA agency. 
Therefore, we adapted slightly smaller and corrected version  -- Czech WordNet 1.9 PDT \citep{czech_wordnet_pdt}, which is publicly available is the LINDAT/CLARIN repository.\footnote{http://hdl.handle.net/11858/00-097C-0000-0001-4880-3} It contains 23,094 synset with nouns, verbs, adjectives, and partly adverbs, 7028 of them contains several entries - paraphrases.

Czech WordNet was derived from the Princeton WordNet \citep{wordnet,fellbaum98wordnet} by automatic translation followed by manual control. 
This method has several disadvantages \citep{1489838} -- even though most of the paraphrases it contains are very high quality, there are also multiword expressions that are not fixed phrases. Next to commonly used words, there are many  paraphrases rarely used in the Czech language and several synsets 
(with names of apostles) were left untranslated for some reason.
\Fref{divny_wordnet} shows examples of such synsets.

\begin{figure*}[tb]
\begin{center}

 \begin{tabular}{ll}
ambulance (798'), sanitka (1295), pohotovost (1304*vetsina s jinym vyznamem), záchranka (957), sanita (138) 
 
very rarely used: (syn2020)
kukuřičný cukr (0) , celeróza (0) 
cheeseburger (59), smažený sýr v housce (1) 
vrtulník (1911), vírník (28), autogyra (0), gyroplán (0)
\end{tabular}

plněná rajčata (4), plněná rajčata na studeno (0)
piezoelektrická přenoska (0), krystalová přenoska (0)
Andrew, Saint Andrew, Saint Andrew the Apostle, St Andrew
želví polévka (4), pravá želví polévka (0) 
monocykl (0), jednokolový velocipéd (0)
topinambur (39), jeruzalémský artyčok (2)
sponka (329), hřebíček na papír (0) 

\caption{Example of the paraphrases in the Czech WordNet. The~hypothesis is grammatically correct 
and has the same meaning as the reference sentence. We analyse both 
sentences to t-layer, where we create a new reference sentence by substituting
synonyms from hypothesis to the reference. In the next step, we will change also
the word order to better reflect the hypothesis.}
\label{divny_wordnet}
\end{center}
\end{figure*}

 
\subsection{Meteor tables} %two large-scale collections of paraphrases
\label{meteori}
Meteor tables were constructed as a part of machine translation evaluation metric METEOR-NEXT \citep{meteor-tables}. 
Apart from Czech, they are available in other four languages - English, German, French and Spanish. 
They all were constructed automatically from parallel data via a pivot phrase method \citep{pivoting}, i.e, to put it simply --  
the more often two phrases translate to a same foreign phrase often, the more likely they are paraphrases of each other.
%they all were acquired pivoting through English on Europarl and CzEng \citep{czeng}.

Compared to Czech Wordnet, the Meteor tables are large in~size, they contain 756,113 phrase pairs. 
However, due to the automatic method of construction, they contain a lot of noise. 
\todo{ukazat jak vznikaji chybne parafraze diky pivot metode}
The noise is particularly apparent among paraphrases with low pivot score.

\textit{svého názoru}  (its opinion) and \textit{šermovat rukama a 
mlátit neviditelného} (to flail one's arms and to beat the invisible one) are 
selected as a paraphrase. \todo{tu to rozsirit do nejake pekne tabulky}

vědecký pracovník v     z vnitřku almary ozval zvuk:4
12 milionů      deseti dny vytahoval holýma rukama
podle svého názoru      dnes kapitán vyhlásil bezpečnostní cvičení pro
.010100989898999999    nemoudré        okrouhlá skla

0.4    důsledků takového       implications of such an
0.4	 qprostředí a vodohospodářství    eaux et

Among one-word paraphrases the noise is sparser, but there are still pairs like 
\textit{1873} - \textit{pijavice} (a leech) or \textit{afgh\'{a}nci} (Afghans) - 
\textit{š\v{t}astně} (happily) identified as synonyms. 

\todo{However, the biggest problem is that most of synonymous pairs were just 
different word forms of the same lemma. We therefore attempt to automatically 
filter the Meteor table, the methods are described in Section \ref{filtering-section}}

\todo{zminit skore, ktere je tam prirazeno, pouziva se dale - The first, straightforward approach is to use the paraphrase scores already 
provided in~Meteor. They are based on~phrasal translation probabilities which 
correspond to~a~paraphrase probability in~the pivoting model.}



Meteor tables were constructed as a part of machine translation evaluation 
metric METEOR-NEXT \citep{meteor-tables}. Apart from Czech, they are available 
in other four languages - English, German, French and Spanish. 
They all were constructed automatically from parallel data via a pivot phrase 
method \citep{pivoting}, i.e, to put it simply -  the more often two phrases 
translate to a same foreign phrase often, the more likely they are paraphrases 
of each other.

Czech Meteor Paraphrase tables contain 756,113 phrase 
pairs, they all were acquired pivoting through English on Europarl and CzEng 
\citep{czeng}.

Compared to Czech Wordnet, the Meteor tables are large in~size, but they 
contain a lot of noise. The noise is particularly apparent among paraphrases 
with low pivot score

\textit{svého názoru}  (its opinion) and \textit{šermovat rukama a 
mlátit neviditelného} (to flail one's arms and to beat the invisible one) are 
selected as a paraphrase. \todo{tu to rozsirit do nejake pekne tabulky}

vědecký pracovník v     z vnitřku almary ozval zvuk:4
12 milionů      deseti dny vytahoval holýma rukama
podle svého názoru      dnes kapitán vyhlásil bezpečnostní cvičení pro
.010100989898999999    nemoudré        okrouhlá skla

0.4    důsledků takového       implications of such an
0.4	 qprostředí a vodohospodářství    eaux et

Among one-word paraphrases the noise is sparser, but there are still pairs like 
\textit{1873} - \textit{pijavice} (a leech) or \textit{afgh\'{a}nci} (Afghans) - 
\textit{š\v{t}astně} (happily) identified as synonyms. 

\todo{However, the biggest problem is that most of synonymous pairs were just 
different word forms of the same lemma. We therefore attempt to automatically 
filter the Meteor table, the methods are described in Section \ref{filtering-section}}

\todo{zminit skore, ktere je tam prirazeno, pouziva se dale - The first, straightforward approach is to use the paraphrase scores already 
provided in~Meteor. They are based on~phrasal translation probabilities which 
correspond to~a~paraphrase probability in~the pivoting model.}


\subsection{PPDB} 