\chapter{Simple substitution method}
\addcontentsline{toc}{chapter}{Simple substitution method}

In this chapter,\footnote{This chapter is based on the article 
\citep{barancikova:2014} he joint work with Rudolf Rosa and Ale\v{s} Tamchyna.
Rudolf was in charge of Depfix and Ale\v{s} performed all experiments with 
alignments. \diff{I did all experiments with paraphrasing, filtering and evaluation.}} 
\diff{we present a simple method of sentence paraphrasing directly inspired by
\cite{kauchak}.} 

Our algorithm, however, differs in several crucial aspects. As Czech belongs 
among~inflective languages with rich morphology, a Czech word has typically 
many forms and the correct form depends heavily on its context, e.g., cases 
of nouns depend on verb valency frames. Therefore, we do not attempt to~change 
a~single word in~a~reference sentence but we focus on~creating one single correct 
reference sentence.

Furthermore, \citet{kauchak} use English WordNet as their source of paraphrases.
The Czech WordNet \citep{czech-wordnet} is substantially smaller, it identifies a
paraphrase in every fifth sentence in our data on average (See \Tref{number_of_substitutions}).
Adding larger paraphrase tables is thus necessary. We exploit --  in~addition 
to~the Czech WordNet --  the~Czech Meteor tables \citep{meteor-tables}.  
Because of noise in the Czech Meteor tables, we experiment with adding alignment
between the hypothesis and the corresponding reference sentence \Sref{filtering-section}.

The method is evaluated on WMT12 a WMT13 data.

In \Sref{algorithm}, we present several algorithms for lexical and phrase 
substitutions. They consists of three steps:

\begin{itemize}
\item selecting possible paraphrase candidates, 
\item paraphrasing, i.e. the substitution of the paraphrase candidates,
\item application of Depfix to fix grammatical errors caused by the paraphrasing.
\end{itemize}

These algorithms are used in \Sref{filtering-section} in an experiment with
automatic filtering of the Meteor Tables.

First, the algorithm for lexical and phrase substitutions is described in \Sref{algorithm}.
It consists of three parts -- a paraphrase candidate selection (greedy or using an alignment),
the substitution itself



We first present algorithm for lexical and phrase substitutions. It includes two methods
for paraphrase candidate selection, three method of paraphrasing differing in the order
of substitutions


or lexical (one-word) and phrase 
substitution based on phrasal alignment and tables of~synonymous 
expressions. 

The algorithm is described in \Sref{algorithm}.

%\todo{Further, we apply Depfix -- the system originally designed 
%for automatic correction of~grammatical errors that appear often in English-to-Czech 
%MT outputs, on newly created paraphrases.} 
\todo{uvod zcela preformulovat a rozsirit, smysluplne v nem popsat cely experiment}
This method is independent of an evaluation metric. We use BLEU score in our 
experiments because of its widespread application.  We show that in spite of the 
simplicity of the method, BLEU achieves a significant improvement in its 
correlation with human judgment using our new reference sentences (\Sref{results}).

Instead of the contextual evaluation, we focus on keeping grammatical 
correctness and the original meaning by using Depfix \citep{depfix} -- an 
automatic post-editing system which is able to fix Czech sentences containing 
grammatical errors. Depfix was originally designed for post-editing outputs of 
English-to-Czech phrase-based machine translation. We adapted it to fit our 
setting (\Sref{depfix}).

Furthermore, \citet{kauchak} use English WordNet as their source of paraphrases.
The Czech WordNet \citep{czech-wordnet} is substantially smaller, it identifies a
paraphrase in every fifth sentence in our data on average (See 
\Tref{number_of_substitutions}). Adding larger paraphrase tables was thus necessary.
We exploit --  in~addition to~the Czech WordNet --  Czech Meteor tables 
\citep{meteor-tables}.  Because of noise in the Czech Meteor tables, we 
experiment with adding alignment between the hypothesis and the corresponding 
reference sentence \Sref{filtering-section}.


\begin{table}[t]
\begin{center}
\begin{tabular}{lcc}
& \textbf{WMT12} & \textbf{WMT13} \\
\hline
\multicolumn{1}{l|}{WordNet}      &  \multicolumn{1}{c|}{780} & 650 \\
\multicolumn{1}{l|}{filtered Meteor}   & \multicolumn{1}{c|}{4,588} & 3,877 \\
\hline
\multicolumn{3}{c}{} \\[-14pt]
\hline
\multicolumn{1}{l|}{their union}       & \multicolumn{1}{c|}{4,766} & 4,013 \\
\end{tabular}
\caption{The average number of words pairs identified as~paraphrases between 
a~hypothesis and a~corresponding reference sentence according to~their source.}
\label{number_of_substitutions}
\end{center}
\end{table}


\section{Algorithms}
\label{algorithm}
We experiment with several algorithms for paraphrasing reference sentences. 
They differ in the method for selecting potential paraphrase pairs and in the 
length of paraphrases.

\subsection{Candidate Selection}
We select potential paraphrases using two different methods. The first one is a 
simple greedy search similar to~\citet{kauchak}, the other one uses automatic word
alignment for selecting corresponding segments of~the reference sentence and the 
hypothesis.

\subsubsection{Simple Greedy Method}
\diff{First, we perform morphological analysis and tagging of hypotheses and 
reference sentences from WMT12 a WMT13 using Morče \citep{morce:2007}. 
We need all sentences in lemmatized forms for two reasons -- we do not want 
to select as paraphrases different word forms of a single lemma and second, 
paraphrases in the Czech WordNet and the filtered Czech Meteor tables are 
represented in form of lemmas too.}

Let $ H_{L} $, $ R_{L} $ be sets of lemmas from a hypothesis and a reference 
sentence, respectively. Then, one-word paraphrase candidates are chosen as:

\begin{equation*}
C_{L} = \{(r,h) \, | \, r \in R_{L} \setminus H_{L} \wedge h \in H_{L} \setminus R_{L} \} 
\end{equation*}

\diff{Multi-words candidates $ C_M $ are selected as the Cartesian product of all 
sequences from the reference sentence and all sequences from the hypothesis. 
The maximum sequence length is seven words, which corresponds to the length 
of~the longest paraphrases in~the Czech Meteor tables. In~contrast to $C_{L}$, 
$ C_M $ is chosen directly from sequences of word forms, not lemmas.} Formally:

Let $ h_1,...,h_m $, $ r_1,..., r_n $  be a hypothesis and a reference sentence,
respectively. Then the set of multi-word paraphrase candidates is selected the 
following way:

\begin{align*}
  C_{M} = \{ (<r_i,..,r_{i+x}>,<h_j,...,h_{j+y}>) \, | \, 1 \leq i \leq n-x \, \wedge \\ 
    \: 1~\leq~j \leq m-y  \: \wedge \: 0 \leq x,y \leq 6 \: \wedge \: (x \neq 0 \vee y \neq 0) \}
  \end{align*}
  
\diff{Example of one-word a multiword candidates are presented in \Fref{candidates_example}.}

\begin{figure}[t]

\begin{center}
\begin{tabular}{r|l}
 Source &  \begin{tabular}{l}
  	\textit{The location alone is classic.} \\
	\end{tabular} \\
 \hline
 
 Hypothesis & \begin{tabular}{llll}
 			\textit{Samotné} & \textit{místo} & \textit{je} & \textit{klasické.} \\
 			Actual & place & is & classic \\
			\end{tabular} \\
 &  \begin{tabular}{l}
  	The place alone is classic. \\
	\end{tabular} \\

 \hline
 Reference & \begin{tabular}{llll}
 			\textit{Už} & \textit{poloha} & \textit{je} & \textit{klasická.} \\
 			Already & position & is & classic. \\
			\end{tabular} \\
 &  \begin{tabular}{l}
  	The position itself is classic. \\
	\end{tabular}  \\ 

 \hline
  $ H_{L} $ &  \{samotný, místo, být, klasický\}   \\
 \hline 
   $ R_{L} $ & \{už, poloha, být, klasický\}  \\
 \hline  
   $C_{L} $  &  \{(už,samotný), (už,místo), (poloha,samotný), (poloha,místo)\} \\
 \hline  
    & \{(už, samotné místo), (už, samotné místo je), \\
  & (už, samotné místo je klasické),  (už poloha, samotné), \\
   $C_{M} $ &  \multicolumn{1}{c}{...}\\
 & (klasická, samotné místo je klasické),  (klasická, místo je), \\
 & (klasická, místo je klasické),  (klasická, je klasické)\}  \\
 \hline
 
\end{tabular}
\caption{\diff{Example of the candidate selection methods on a hypothesis and a 
reference sentence from WMT11. Note that $C_{M}$ is substantially shortened --
there are 84 sequence pairs in the full version of $C_{M}$.}}
\label{candidates_example}
\end{center}
\end{figure}



\subsubsection{Word and Phrase Alignments}

One possible way to make the algorithm more reliable is to restrict the
application of paraphrases to words/phrases which are aligned to each other. 
We compute word alignment between reference translations and the sets of
hypotheses using GIZA++ \citep{gizapp}.

If we used only hypotheses with corresponding reference sentences to create the 
alignment, the alignment quality would be insufficient.\footnote{13 MT systems x 
3003 sentences from WMT12 + 12 MT systems x 3000 sentences from WMT13
= only 75039 sentence pairs)} In order to make the training data for word 
alignment larger, we take advantage of the fact that all outputs are 
translations of the same data and also add all pairs of system outputs to our 
data, creating over 1,000,000 \equo{artificial} sentence pairs.\footnote{We 
also experiment with adding much larger synthetic parallel data created by 
machine translation (note that we need Czech-Czech data) but there was no 
impact on the quality of paraphrasing so we follow the outlined approach which 
requires no additional data or processing.} For example, the parallel data for 
WMT12 then looks as follows:

\begin{center}
\begin{tabular}{ll}
Source & Target \\
\hline
system 1 & reference \\
system 1 & system 2 \\
... & ...\\
system 1 & system 13 \\
system 2 & reference \\
system 2 & system 1 \\
system 2 & system 3 \\
... & ... \\
system 13 & system 12 \\
\end{tabular}
\end{center}

The set of~one-word candidates $C_L$ is then simply the set of all word pairs such
that there exists an alignment link between them. The set $C_M$ is extracted
using phrase extraction for phrase-based MT, the standard consistency criterion
is~applied \citep{Och99improvedalignment}.

\subsection{Paraphrasing}
\diff{We reduce the set of one-word candidates $ C_{L} $ to pairs appearing in the 
Czech WordNet and in the filtered Czech Meteor tables\footnote{The process of 
filtering the Meteor tables is described later in \Sref{filtering-section} as it uses
the paraphrasing methods described in this section.} in the following way. 
If~a~word appears in several synonymous pairs we give preference 
to those found in~the WordNet or even better in the intersection of paraphrases 
from the WordNet and the filtered Meteor. Similarly, we filter multi-word 
candidates $ C_{M} $ to pairs contained in the Meteor tables.}

We evaluate three different paraphrasing methods which differ in the order of
substitution.

\begin{description}
\item[One-word only] We proceed word by word from the beginning of the 
reference sentence to~its end. If a~lemma of~a~word appears as~the first member 
of~a~pair in reduced $ C_{L} $, it is replaced by~the word form from the 
hypothesis that has its lemma as the second element of~that pair, i.e., 
paraphrase from the hypothesis. Otherwise, we keep the original word from the 
reference sentence.
\item[One-word first] We use \textit{One-word only} and then we apply longer 
paraphrases. In that case we move ahead from the longest paraphrases to the 
shortest. That is because Meteor contains often even subsequences of~phrases 
and we could substitute, instead of~whole phrase, only a part of~it. We do not 
attempt to replace any word that was already changed before.
\item[Multi-word first] We substitute the longest confirmed paraphrases from
$ C_{M} $ and move to the shorter ones. We replace again only sequences that 
have not been substituted yet. After this, we paraphrase the remaining 
unchanged words with the \textit{One-word only} method.
\end{description}

\subsection{Depfix}
\label{depfix}
Depfix is an automatic post-editing system, originally designed for improving 
the quality of phrase-based English-to-Czech machine translation outputs. For
more details see \Sref{depfix}.

We observe that errors that appear in outputs of our paraphrasing algorithms 
are often similar to errors appearing in outputs of phrase-based machine 
translation systems, e.g. errors in morphological agreement are very common.
This makes Depfix a valuable tool for fixing \diff{substitution} errors, since typical
grammar correcting tools, such as a grammar-checker in a word processor,
focus on errors that are typical for humans, not for machines.

Also, the fact that Depfix exploits English source sentences is an advantage 
in our case, as opposed to other grammar correcting tools, which typically do 
not have access to an English source and therefore, can not use it to improve 
their performance. For this reason, we apply Depfix post-editing to fix the 
errors in grammar that frequently appear in our outputs.

However, some error types that are common in phrase-based machine translation, 
such as errors in preserving the correct verb tense, do not frequently emerge in the 
paraphrasing process.
Therefore, we experiment with two Depfix configurations in this work:
\begin{description}
\item[full] the original Depfix system with all 33 fixing blocks,
as~described in \cite{rosa:mgr}
\item[limited] after analyzing 50 randomly selected sentences, we find out that 
Depfix not only fixes errors but also introduces new ones. Most of these errors 
include changes that are essential while translating from English (such as 
adding negation); however, they appear redundant for paraphrasing. After 
manual examination, we adapted Depfix for fixing paraphrasing errors by 
disabling 10 fixing blocks\footnote{The following fixing blocks are disabled
in limited Depfix: Fixing reflexive tantum, Fixing morphological number of 
nouns, Translation of \equo{by}, Translation of \equo{of}, Translation of 
present continuous, Subject categories projection, Missing reflexive verbs, 
Subject personal pronouns dropping, Tense translation, Negation translation}
that cause the majority of incorrect alterations.

%onkretne na 50 nahodne vybranejch vetach to udelalo 22 dobrych zmen a 47 spatnych.
% Je ale fakt, ze hodne tech zmen se tyka chyb, ktery jsou asi nutny u prekladu z anglictiny,
% ale tu nemaji smysl - to je treba pridavani negace (u sloves i adjektiv), nebo zmeny v case u sloves.


\end{description}

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.55]{../img/filtering-lexical-cropped.pdf}
\caption{Comparison of automatic filtering techniques for~\emph{one-word} paraphrases on WMT12 data.}
\label{fig:filtering-lexical}
\end{center}
\end{figure}

\begin{figure}[ht]
\begin{center}
\includegraphics[scale=0.55]{../img/filtering-mwe-cropped.pdf}
\caption{Automatic filtering of multi-word paraphrase for~the \textit{multi-word-first} scenario on WMT12 data.}
\label{fig:filtering-mwe}
\end{center}
\end{figure}

\section{Filtering the Meteor Tables}
\label{filtering-section}

We try to remove the noise from the Czech Meteor tables with two different methods. The first
one is based on manual error analysis and it is applied to~one-word pairs only.
The second one is fully automatic and can be applied on all data, but its 
results are inconclusive. Therefore, we employ only the first method in the rest 
of our experiments.

\subsection{Error-analysis Based Filtering}
We manually examine sentences after paraphrasing using only Meteor tables. 
Based on our observation, we perform the following operations on pairs of 
one-word paraphrases from the Meteor tables:

\begin{itemize}
\item morphological analysis using Morče \citep{morce:2007} and replacing of 
word forms with their lemmas; 
\item removing pairs of identical lemmas;
\item removing pairs with different part of speech;
\item removing pairs of unknown words (typically foreign words).
\end{itemize}

The last two rules have a single exception -- paraphrases consisting of numeral 
and corresponding digits, e.g., \textit{osmnáct} (eighteen) and \textit{18}.\footnote{
\textit{0smnáct} has the part of speech \textit{C}, which is designated for numerals, 
\textit{18} is marked with \textit{X} meaning it is an unknown word for the 
morphological analyzer.} These paraphrases are very common in the data. 

This way we reduce more than 160,000 pairs of one word paraphrases to only 
32,154 couples of lemmas.
% \todo{BUD VYMAZAT, NEBO SPRAVNE NALINKOVAT: All examples of bad one-word paraphrases from Subsection \ref{meteori} are removed. }

\subsection{Automatic Filtering}
Filtering strategies described in~this section are based on assigning a score 
to~each paraphrase pair. We then gradually remove paraphrases with low scores 
and measure the effect on~the final correlation of~our metric.

The first, straightforward approach is to use the paraphrase scores already
provided in Meteor. They are based on~phrasal translation probabilities
and it corresponds to~paraphrase probability in~the pivoting model.

We propose an alternative scoring based on pivoting and lexical translation
scores:

$$\text{lex\_p}(\mathbf{s},\mathbf{t}) = \sum_{s \in \mathbf{s}}\sum_{t \in
\mathbf{t}}\sum_{pivot}\text{lex}(s|pivot)\text{lex}(pivot|t)$$

In this case, pivots are all words aligned to both $s$ and $t$ in the parallel
data. To get lexical translation probabilities, we use maximum likelihood
estimation from single best word alignment computed on CzEng 1.0
\citep{czeng10:lrec2012}. We refer to this score as \emph{lexical
pivoting}.

We use random selection as the baseline -- paraphrases are simply shuffled and 
we then use the first 10, 20,$\ldots$ percent of them.

We only evaluate the filtering techniques on the WMT12 data. First, we attempt
to filter one-word paraphrases and use the cleaner paraphrase table in the
\emph{one-word-only} paraphrasing strategy. Note that our paraphrase table has
already been filtered using the error-analysis based filtering described above.

\Fref{fig:filtering-lexical} shows the performance of different filtering
techniques for one-word paraphrases. Relying on Meteor scores proves worse than
random selection. Using lexical pivoting, we can keep a high correlation even 
if we throw away as much as 80\% of the paraphrases, however we do not improve
(by~a~relevant margin) upon the baseline correlation of 0.802 achieved by
\emph{one-word-only} paraphrasing with the full paraphrase table.

We evaluate the best-performing technique also in the \textit{multi-word-first}
scenario where we use it for filtering multi-word paraphrases (see
\Fref{fig:filtering-mwe}). As we reduce the number of paraphrases, we observe a
considerable improvement of~correlation, however we never outperform
\textit{one-word-only} or \textit{one-word-first}. In this case, the filtering
simply mitigates the damage done by the multi-word paraphrases. We
cannot hope to achieve a higher score without a~more fine-grained grip on what
a~good multi-word paraphrase is.

\section{Results}
\label{results}

\begin{table*}[htb]
\begin{center}
\scalebox{0.99}{
\begin{tabular}{l|ccc|ccc}
\multicolumn{7}{c}{\textbf{WMT12}}\\
\hline
Method & \multicolumn{3}{c|}{Greedy selection} & \multicolumn{3}{c}{Word alignment} \\
\hline
Depfix & No  & Full  & Limited & No  & Full  & Limited\\
\hline
One-word only     & 0.80 & \textbf{0.83} & \textbf{0.83} & 0.79 & 0.81 & 0.81 \\
One-word first    & 0.79 & 0.82 & 0.82 & 0.77 & 0.79 & 0.80 \\
Multi-word first & 0.77 & 0.81 & 0.80 & 0.76 & 0.78 & 0.78 \\
\end{tabular}}
\vspace{10pt}
Baseline~correlation: \textbf{0.75}
\vspace{10pt}

\scalebox{0.99}{
\begin{tabular}{l|ccc|ccc}
\multicolumn{7}{c}{\textbf{WMT13}}\\
\hline
Method & \multicolumn{3}{c|}{Greedy selection} & \multicolumn{3}{c}{Word alignment} \\
\hline
Depfix & No  & Full  & Limited & No  & Full  & Limited\\
\hline
One-word only   & 0.86 & \textbf{0.89} & 0.88 & 0.86 & 0.88 & 0.87 \\
One-word first   & 0.85 & 0.88 & 0.88 & 0.83 & 0.87 & 0.86 \\
Multi-word first  & 0.84 & 0.87 & 0.86 & 0.83 & 0.87 & 0.86 \\
\end{tabular}}
Baseline~correlation: \textbf{0.83}

\caption{Pearson's correlation of BLEU and the silver standard.}
\label{corrs:12:13}
\end{center}
\end{table*}


Results of our method are presented in \Tref{corrs:12:13}. The~baseline 
(i.e., using the original reference sentences) has a correlation of 0.75, 0.83
respectively. All evaluated approaches outperform it, the simplest one 
\textit{One-word only} performs the best (\Fref{example} shows an example of 
this method).

\begin{figure}[t]

\begin{center}
\begin{tabular}{ll}
 Source &  \begin{tabular}{l}
  	\textit{The location alone is classic.} \\
	\end{tabular} \\
 \hline
 
 Hypothesis & \begin{tabular}{llll}
 			\textit{Samotné} & \textit{místo} & \textit{je} & \textit{klasické.} \\
 			Actual & place & is & classic \\
			\end{tabular} \\
 &  \begin{tabular}{l}
  	The place alone is classic. \\
	\end{tabular} \\

 \hline
 Reference & \begin{tabular}{llll}
 			\textit{Už} & \textit{poloha} & \textit{je} & \textit{klasická.} \\
 			Already & position & is & classic. \\
			\end{tabular} \\
 &  \begin{tabular}{l}
  	The position itself is classic. \\
	\end{tabular}  \\ 

 \hline
  New reference & \begin{tabular}{llll}
 			\textit{Už} & \textit{místo} & \textit{je} & \textit{klasická.} \\
 			Already & place & is & classic \\
			\end{tabular} \\
 &  \begin{tabular}{l}
  	*The place itself is classic. \\
	\end{tabular} \\
 \hline 
  Depfixed ref. & \begin{tabular}{llll}
 			\textit{Už} & \textit{místo} & \textit{je} & \textit{klasické.} \\
 			Already & place & is & classic \\
			\end{tabular} \\
 &  \begin{tabular}{l}
  	The place itself is classic. \\
	\end{tabular} \\
 \hline  
 
\end{tabular}
\caption{Example of the \textit{One-word only} method. The~hypothesis is 
grammatically  correct and has very similar meaning as the reference sentence. 
The new reference is closer in wording to the hypothesis, but there is no 
agreement between the noun and adjective. Depfix resolves the error and the 
final reference is correct and much more similar to~the hypothesis.}
\label{example}
\end{center}
\end{figure}

We use a test for comparing correlated correlation coefficients 
\citep{meng1992comparing} to determine whether the difference in correlation
coefficients is statistically significant. The test shows that BLEU performs
better with our reference sentences with 99\% certainty. 

Multi-word paraphrases are very noisy and while they do bring the system 
outputs closer to the reference (the average BLEU score of the systems 
increases), they often propose non-equivalent translations or violate the 
correctness of the sentence, thus blurring the differences between systems.

When paraphrasing is restricted by word alignment, all methods perform worse. 
As \Tref{substitutions:12:13} shows, the number of applied paraphrases is much
lower: while the proportion of correct paraphrases is higher, their amount is 
reduced too much and overall, our technique is harmed by this restriction. 

\begin{table*}[htb]
\begin{center}
\begin{tabular}{l|cc|cc}
\multicolumn{5}{c}{\textbf{WMT12}}\\
\hline
\multirow{2}{*}{Method} & \multicolumn{2}{c|}{Greedy selection} & \multicolumn{2}{c}{Word alignment} \\
& Words & Phrases & Words & Phrases \\
\hline
One-word only     & 1.59 & --   & 0.86 &  --  \\
One-word first    & 1.59 & 0.23 & 0.86 & 0.22 \\
Multi-word first  & 1.38 & 0.31 & 0.81 & 0.27 \\
\end{tabular}
\vspace{10pt}
\begin{tabular}{l|cc|cc}
\multicolumn{5}{c}{\textbf{WMT13}}\\
\hline
\multirow{2}{*}{Method} & \multicolumn{2}{c|}{Greedy selection} & \multicolumn{2}{c}{Word alignment} \\
& Words & Phrases & Words & Phrases \\
\hline
One-word only    & 1.33 &  --  & 0.76 & --   \\
One-word first   & 1.33 & 0.20 & 0.76 & 0.20 \\
Multi-word first & 1.04 & 0.68 & 0.74 & 0.24 \\
\end{tabular}

\caption{Average number of replaced words/phrases per~sentence for each method 
on data from WMT12 and WMT13.}
\label{substitutions:12:13}
\end{center}
\end{table*}

On the other hand, applying Depfix is always beneficial, with the positive 
effects ranging from 0.02 up to 0.04. This supports our assumption of the 
importance of grammatical correctness of the created references. However, 
the \textit{limited} version although carefully selected, shows no improvement
over the \textit{full} version in most cases.

Results on the data from WMT12 and WMT13 are consistent. Paraphrasing 
helps to increase the accuracy of the evaluation, even though the differences on 
the WMT13 data are not as~big due to much higher baseline. This is also reflected 
in~the smaller amount of substitutions (see \Tref{substitutions:12:13}).

\section{Conclusion}
%Big difference in meteor (mozna zkusit jeste nejakou statistiku, jak casto dochazelo
%k substituci z meteoru a jak casto dochazi k substituci z meteoru x wordnetu? aby bylo
%opravdu mozne, ze ta filtrace vyznamne prispela??
Our results confirm the positive impact of paraphrasing a~reference sentence 
on~the performance of~the BLEU score. We~evaluate a number of approaches 
to~paraphrasing. The best results are achieved by the \textit{one-word only} 
greedy substitution method. We achieve a statistically significant improvement 
in the evaluation of English-to-Czech MT. 

We illustrate several methods for reducing noise in a paraphrase corpus and
we confirm importance of grammar correctness of reference sentences in MT 
evaluation by the improvement of correlation after applying Depfix.

%In the future, we plan to further increase the correlation by creating our own 
%Czech paraphrase tables that would be larger than Czech WordNet, but less noisy 
%than Czech Meteor Tables.

%Another way to improve the performance of our system which we want to follow
%is a further adaptation of the Depfix system to our task. We intend to
%tune existing Depfix corrections, as well as to add new corrections specific
%to our task. We would also like to devise a way of~informing Depfix which parts
%of the sentences come from the reference and which come from the paraphrasing
%to eliminate \equo{false positives}, i.e. Depfix attempting to correct words
%that are unlikely to be incorrect.
